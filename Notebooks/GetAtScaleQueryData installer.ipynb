{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "executionInfo": {
          "elapsed": 314,
          "status": "ok",
          "timestamp": 1729000261933,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "SB8018zyuM0Q"
      },
      "outputs": [],
      "source": [
        "# prep imports\n",
        "from google.cloud import bigquery\n",
        "import requests\n",
        "import datetime\n",
        "from dateutil import parser\n",
        "import warnings\n",
        "import pandas as pd\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1729000262228,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "PaCKgS2mwlPQ"
      },
      "outputs": [],
      "source": [
        "# Set up variables\n",
        "project_id    = 'atscale-sales-demo'\n",
        "dataset_id    = 'mm_dataset'\n",
        "table_queries = 'twinpines_queries_installer'\n",
        "table_queries_full = project_id + '.' + dataset_id + '.' + table_queries\n",
        "\n",
        "hostname = \"https://52.249.223.76:10502\"\n",
        "bearer_token = 'eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyIwYTJiMjNmMi00ZmYxLTQ3MmMtNzllZS02ZDg3NWRkMzg1ZWEiOnsicXVlcnlfZGF0YXNldF9hcGlfYWxsb3dlZCI6dHJ1ZSwiZGVzaWduX2NlbnRlcl9hcGlfYWxsb3dlZCI6dHJ1ZX0sImFwaXN1cGVydXNlciI6dHJ1ZSwiYXV0aGVudGljYXRlZCI6dHJ1ZSwiYzk4YzI5NTYtYTJiMC00YjA5LTQ1NzctODQ5ZDBmMDY1YzMxIjp7InF1ZXJ5X2RhdGFzZXRfYXBpX2FsbG93ZWQiOnRydWUsImRlc2lnbl9jZW50ZXJfYXBpX2FsbG93ZWQiOnRydWV9LCJkZWZhdWx0Ijp7InF1ZXJ5X2RhdGFzZXRfYXBpX2FsbG93ZWQiOnRydWUsImRlc2lnbl9jZW50ZXJfYXBpX2FsbG93ZWQiOnRydWV9LCJleHAiOjE3MjkwMDI5NzEsImltcGVyc29uYXRpb25zIjp7Im9yZ19pbXBlcnNvbmF0aW9uIjpudWxsfSwiaXNzdWVfdGltZSI6MTcyODk5OTM3MSwicGVybWlzc2lvbnMiOnsib3JnX3Blcm1pc3Npb25zIjp7ImM5OGMyOTU2LWEyYjAtNGIwOS00NTc3LTg0OWQwZjA2NWMzMSI6eyJhZ2dyZWdhdGVzLm1hbmFnZSI6dHJ1ZSwiYWdncmVnYXRlcy52aWV3Ijp0cnVlLCJkYXRhd2FyZWhvdXNlcy5hZG1pbiI6dHJ1ZSwiZGVzaWduY2VudGVyLnVzZXIiOnRydWUsImdsb2JhbC5wcm9qZWN0LmVkaXQiOnRydWUsImdsb2JhbC5wcm9qZWN0LnB1Ymxpc2giOnRydWUsImdsb2JhbC5wcm9qZWN0LnB1Ymxpc2hlZC5yZWFkIjp0cnVlLCJvYmplY3QuY3JlYXRlIjp0cnVlLCJvcmdhbml6YXRpb24uYWRtaW4iOnRydWUsIm92ZXJyaWRlLmVuZ2luZS5hbmQub3JnYW5pemF0aW9uLnNldHRpbmdzIjp0cnVlLCJxdWVyaWVzLm1hbmFnZSI6dHJ1ZSwicXVlcmllcy52aWV3Ijp0cnVlLCJydW50aW1lLnVzZXIuc2V0dGluZ3MiOnRydWUsInZpZXcuc3VwcG9ydC5sb2dzIjp0cnVlfSwiZGVmYXVsdCI6eyJhY2Nlc3MubWV0cmljcy5kYXNoYm9hcmQiOnRydWUsImFnZ3JlZ2F0ZXMubWFuYWdlIjp0cnVlLCJhZ2dyZWdhdGVzLnZpZXciOnRydWUsImRhdGF3YXJlaG91c2VzLmFkbWluIjp0cnVlLCJkZXNpZ25jZW50ZXIudXNlciI6dHJ1ZSwiZ2xvYmFsLnByb2plY3QuZWRpdCI6dHJ1ZSwiZ2xvYmFsLnByb2plY3QucHVibGlzaCI6dHJ1ZSwiZ2xvYmFsLnByb2plY3QucHVibGlzaGVkLnJlYWQiOnRydWUsIm9iamVjdC5jcmVhdGUiOnRydWUsIm9yZ2FuaXphdGlvbi5hZG1pbiI6dHJ1ZSwib3ZlcnJpZGUuZW5naW5lLmFuZC5vcmdhbml6YXRpb24uc2V0dGluZ3MiOnRydWUsInF1ZXJpZXMubWFuYWdlIjp0cnVlLCJxdWVyaWVzLnZpZXciOnRydWUsInJ1bnRpbWUudXNlci5zZXR0aW5ncyI6dHJ1ZSwidmlldy5zdXBwb3J0LmxvZ3MiOnRydWV9fX0sInN1YiI6ImFkbWluIiwic3VwZXJ1c2VyIjp0cnVlfQ.aBJGOwBin1Kk-QaEGUuuYruO_hJ7Tt7pUeu8GUK905hOykoFWCthLjC6YLWoyGlbT9E2X548kntVoczXwpu8n1Te8TmgOn50TF6yA9zjgzivm3DPdrIcjtFIouQ00M76jqpzhyueHAww3yvzvyEzvytQ2L_BC0f1FLdsxhaGiNYFBNtY4702MMV9rYxUO4Rh24-IEVRT_9Ayl99MtgYJc_8HekvWf1qyOQljw2aNBRa6z31lGGtIBeKjdihVuCdF84khz-Oi1EjdTTXUU_bWdrkiJdRZaChUkIHZ1wMLoljD0G8mjzby2UDvufws_3gXc_nXNFAWYlNezAdCaUNqPA'\n",
        "full_load_hours = 3600 #max limit from atscale <168\n",
        "maxQueriesPerCall= 9999"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1729000262228,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "VGOojSa5xn3a"
      },
      "outputs": [],
      "source": [
        "#Create GBQ Client\n",
        "client = bigquery.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "executionInfo": {
          "elapsed": 278,
          "status": "ok",
          "timestamp": 1729000262505,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "OI1KZ0joxftU"
      },
      "outputs": [],
      "source": [
        "#get last load max datetime\n",
        "lastload_record = None\n",
        "sql_query = f'SELECT received_time FROM `{table_queries_full}` order by received_time DESC limit 1;'\n",
        "\n",
        "query_job = client.query(sql_query)\n",
        "try:\n",
        "  results = query_job.result()\n",
        "  for row in results:\n",
        "    lastload_record = row\n",
        "    break\n",
        "except:\n",
        "  lastload_record = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "executionInfo": {
          "elapsed": 305,
          "status": "ok",
          "timestamp": 1729000262807,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mTyxI_FNyL_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b493c705-823b-422d-ad75-920b9d57f7cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'load from: 2024-05-18T13:51:02.448161Z'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 329
        }
      ],
      "source": [
        "lastload = (datetime.datetime.now() - datetime.timedelta(hours=full_load_hours)).isoformat() +'Z'\n",
        "\n",
        "if lastload_record:\n",
        "  lastload = lastload_record['received_time']\n",
        "\n",
        "'load from: ' + lastload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3204,
          "status": "ok",
          "timestamp": 1729000266005,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "7viptkMQcdeg",
        "outputId": "9c31a1b2-7855-49ef-83d9-28da8639155e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://52.249.223.76:10502/monitoring/queries/orgId/default?queryStartTimeFrom=2024-05-18T13:51:02.448161Z&maxInboundQueries=9999&includeQueryText=True\n"
          ]
        }
      ],
      "source": [
        "#load log from atscale\n",
        "url = hostname + \"/monitoring/queries/orgId/default?queryStartTimeFrom=\"+ lastload +\"&maxInboundQueries=\" + str(maxQueriesPerCall) + \"&includeQueryText=True\"\n",
        "print(url)\n",
        "headers = {\n",
        "  'Accept': 'application/zip',\n",
        "  'Authorization': 'Bearer ' + bearer_token\n",
        "\n",
        "}\n",
        "\n",
        "records = []\n",
        "# Start at Page 1\n",
        "current_page = 1\n",
        "\n",
        "# Loop through all the pages\n",
        "while True:\n",
        "    response = requests.request(\"GET\", url, headers=headers, verify=False, params={'page': current_page })\n",
        "    if response.status_code <= 299:\n",
        "      records += response.json()['response']['data']\n",
        "    else:\n",
        "      print(response.text)\n",
        "      raise SystemExit(\"Stop notebook due to API error\")\n",
        "\n",
        "    # End loop if the current page we requested is the same as the last page the API returns\n",
        "    #if current_page == response.json()['totalPages']:\n",
        "    #    break\n",
        "\n",
        "    # Increment the page to request\n",
        "    #current_page =response.json()['totalPages']\n",
        "    current_page += 1\n",
        "    break\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(records) <1:\n",
        "  raise SystemExit(\"No records to update\")"
      ],
      "metadata": {
        "id": "hysbCA0AcLgV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1729000266005,
          "user_tz": -120,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows_denormalized = []\n",
        "\n",
        "subquery_fields = [\n",
        "    'type',\n",
        "    'query_id',\n",
        "    'query_text',\n",
        "    'succeeded',\n",
        "    'started',\n",
        "    'subquery_fetch_start',\n",
        "    'finished',\n",
        "    'dialect',\n",
        "    'used_local_cache',\n",
        "    'is_canary',\n",
        "    'extra_props',\n",
        "    'subquery_wait_duration',\n",
        "    'subquery_exec_duration',\n",
        "    'subquery_fetch_results_duration',\n",
        "    'subquery_wall_duration',\n",
        "    'subquery_wall_running_duration'\n",
        "\n",
        "  ]\n",
        "\n",
        "extra_props_fields = [\n",
        "      'jobId',\n",
        "      'projectId'\n",
        "  ]\n",
        "\n",
        "for record in records:\n",
        "  if 'subqueries' in record.keys():\n",
        "\n",
        "    for subquery in record['subqueries']:\n",
        "\n",
        "      for subquery_field in subquery_fields:\n",
        "        record['subquery_' + subquery_field] = subquery.get(subquery_field)\n",
        "\n",
        "        if 'extra_props' in subquery.keys():\n",
        "\n",
        "          for extra_props_record in subquery['extra_props']:\n",
        "\n",
        "            for extra_props_field in extra_props_fields:\n",
        "              try:\n",
        "                record['subquery_extra_props_'+extra_props_field] = extra_props_record[extra_props_field]\n",
        "              except:\n",
        "                pass\n",
        "      rows_denormalized.append(record)\n",
        "try:\n",
        "  rows_denormalized = pd.DataFrame(rows_denormalized)\n",
        "  rows_denormalized.drop(columns=['subqueries'], inplace=True)\n",
        "except:\n",
        "  pass\n",
        "#rows_denormalized.drop(columns=['aggregate_definition_ids'], inplace=True)\n",
        "#rows_denormalized.drop(columns=['subquery_succeeded'], inplace=True)\n",
        "#rows_denormalized.drop(columns=['subquery_used_local_cache'], inplace=True)\n",
        "#rows_denormalized.drop(columns=['subquery_extra_props'], inplace=True)\n",
        "#rows_denormalized.drop(columns=['subquery_is_canary'], inplace=True)\n",
        "print('rows to add: ' + str(len(rows_denormalized.index)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9-M81TMJ1EH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1729000266322,
          "user_tz": -120,
          "elapsed": 320,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9626fa86-12c9-4cba-dcf8-359abd851d56"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rows to add: 5695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1729000266322,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "pfqJOCtNrPKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53942f4-91e4-4ae0-a9f2-3cb592e32571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate_definition_ids\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SchemaField('type', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('query_id', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('org_id', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('received_time', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('started_planning', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('finished_planning', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('query_finished', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('succeeded', 'BOOLEAN', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('aggregate_definition_ids', 'STRING', 'REPEATED', None, None, (), None),\n",
              " SchemaField('query_language', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subqueries_results_processing_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('query_wall_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('query_pre_planning_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('query_planning_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subqueries_wall_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subqueries_wall_running_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('query_wall_running_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subqueries_first_wait_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_type', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_query_id', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_query_text', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_succeeded', 'BOOLEAN', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_started', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_subquery_fetch_start', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_finished', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_dialect', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_used_local_cache', 'BOOLEAN', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_is_canary', 'BOOLEAN', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_extra_props', 'RECORD', 'NULLABLE', None, None, (SchemaField('jobId', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('projectId', 'STRING', 'NULLABLE', None, None, (), None)), None),\n",
              " SchemaField('subquery_subquery_wait_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_subquery_exec_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_subquery_fetch_results_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_subquery_wall_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('subquery_subquery_wall_running_duration', 'FLOAT', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('project_id', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('cube_id', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('cube_name', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('user_id', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('query_text', 'STRING', 'NULLABLE', None, None, (), None),\n",
              " SchemaField('failure_message', 'STRING', 'NULLABLE', None, None, (), None)]"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ],
      "source": [
        "#Create Big Query Schema\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.bigquery.schema import SchemaField\n",
        "from typing import List\n",
        "\n",
        "def generate_bigquery_schema(df: pd.DataFrame) -> List[SchemaField]:\n",
        "    TYPE_MAPPING = {\n",
        "        \"i\": \"INTEGER\",\n",
        "        \"u\": \"NUMERIC\",\n",
        "        \"b\": \"BOOLEAN\",\n",
        "        \"f\": \"FLOAT\",\n",
        "        \"O\": \"STRING\",\n",
        "        \"S\": \"STRING\",\n",
        "        \"U\": \"STRING\",\n",
        "        \"M\": \"TIMESTAMP\",\n",
        "    }\n",
        "    schema = []\n",
        "    for column, dtype in df.dtypes.items():\n",
        "\n",
        "        val = df[column].iloc[0]\n",
        "\n",
        "        mode = \"REPEATED\" if isinstance(val, list) else \"NULLABLE\"\n",
        "        try:\n",
        "          if isinstance(val, dict) or (mode == \"REPEATED\" and isinstance(val[0], dict)):\n",
        "              fields = generate_bigquery_schema(pd.json_normalize(val))\n",
        "          else:\n",
        "              fields = ()\n",
        "        except:\n",
        "          print(column)\n",
        "        type = \"RECORD\" if fields else TYPE_MAPPING.get(dtype.kind)\n",
        "        schema.append(\n",
        "            SchemaField(\n",
        "                name=column,\n",
        "                field_type=type,\n",
        "                mode=mode,\n",
        "                fields=fields,\n",
        "            )\n",
        "        )\n",
        "    return schema\n",
        "bigquery_schema = generate_bigquery_schema(rows_denormalized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3965,
          "status": "ok",
          "timestamp": 1729000270285,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "-Pxzme4LoXY_",
        "outputId": "ffdfbc3c-0e65-425d-8214-8eea80bc7297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5695 rows and 40 columns to atscale-sales-demo.mm_dataset.twinpines_queries_installer\n"
          ]
        }
      ],
      "source": [
        "#Write query log records to gbq\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    # Specify a (partial) schema. All columns are always written to the\n",
        "    # table. The schema is used to assist in data type definitions.\n",
        "    schema=bigquery_schema,\n",
        "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
        "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
        "    # disposition it replaces the table with the loaded data.\n",
        "    write_disposition=\"WRITE_APPEND\",\n",
        ")\n",
        "\n",
        "job = client.load_table_from_dataframe(\n",
        "\n",
        "    rows_denormalized, table_queries_full, job_config=job_config\n",
        ")  # Make an API request.\n",
        "job.result()  # Wait for the job to complete.\n",
        "\n",
        "table = client.get_table(table_queries_full)  # Make an API request.\n",
        "print(\n",
        "    \"Loaded {} rows and {} columns to {}\".format(\n",
        "        table.num_rows, len(table.schema), table_queries_full\n",
        "    )\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "name": "GetAtScaleQueryData installer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 395,
          "status": "ok",
          "timestamp": 1726060311277,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "SB8018zyuM0Q"
      },
      "outputs": [],
      "source": [
        "# prep imports\n",
        "from google.cloud import bigquery\n",
        "import requests\n",
        "import datetime\n",
        "import warnings\n",
        "import pandas as pd\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1726060311747,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "PaCKgS2mwlPQ"
      },
      "outputs": [],
      "source": [
        "# Set up variables\n",
        "project_id    = 'atscale'\n",
        "dataset_id    = 'atscale_dataset'\n",
        "table_queries = 'atscale_queries'\n",
        "table_queries_full = project_id + '.' + dataset_id + '.' + table_queries\n",
        "\n",
        "hostname = \"{https://atscale}\"\n",
        "bearer_token = '{api token }'\n",
        "full_load_hours = 167 #max limit from atscale <168"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1726060311747,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "VGOojSa5xn3a"
      },
      "outputs": [],
      "source": [
        "#Create GBQ Client\n",
        "client = bigquery.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1913,
          "status": "ok",
          "timestamp": 1726060313659,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "OI1KZ0joxftU",
        "outputId": "57c173c6-eafe-427d-b83f-d53c4c69ee7e"
      },
      "outputs": [],
      "source": [
        "#get last load max datetime\n",
        "\n",
        "sql_query = f'SELECT main_startTime FROM `{table_queries_full}` order by main_startTime DESC limit 1;'\n",
        "\n",
        "query_job = client.query(sql_query)\n",
        "try:\n",
        "  results = query_job.result()\n",
        "  for row in results:\n",
        "    lastload = row\n",
        "\n",
        "except:\n",
        "  lastload = None\n",
        "lastload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1726060313659,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mTyxI_FNyL_h"
      },
      "outputs": [],
      "source": [
        "if not(lastload):\n",
        "  lastload = str(datetime.datetime.now() - datetime.timedelta(hours=full_load_hours))\n",
        "else:\n",
        "  lastload = str(lastload['main_startTime'].strftime(\"%Y-%m-%d, %H:%M:%S.%f\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 14321,
          "status": "ok",
          "timestamp": 1726060327978,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "7viptkMQcdeg",
        "outputId": "01848581-7f2b-44ba-bd22-e46f315f1ce4"
      },
      "outputs": [],
      "source": [
        "#load log from atscale\n",
        "url = hostname + \"/api/queries?showCanaries=false&startDate=\"+ lastload\n",
        "print(url)\n",
        "headers = {\n",
        "  'Accept': 'application/json',\n",
        "  'Authorization': 'Bearer ' + bearer_token\n",
        "}\n",
        "\n",
        "records = []\n",
        "# Start at Page 1\n",
        "current_page = 1\n",
        "\n",
        "# Loop through all the pages\n",
        "while True:\n",
        "    response = requests.request(\"GET\", url, headers=headers, verify=False, params={'page': current_page })\n",
        "    if response.status_code <= 299:\n",
        "      records += response.json()['results']\n",
        "    else:\n",
        "      print(response.text)\n",
        "      raise SystemExit(\"Stop notebook due to API error\")\n",
        "\n",
        "    # End loop if the current page we requested is the same as the last page the API returns\n",
        "    if current_page == response.json()['totalPages']:\n",
        "        break\n",
        "\n",
        "    # Increment the page to request\n",
        "    #current_page =response.json()['totalPages']\n",
        "    current_page += 1\n",
        "\n",
        "records\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 62,
          "status": "ok",
          "timestamp": 1726060327978,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "f2icob6zd6ng",
        "outputId": "82242f15-5cd2-4a50-d0c3-ac2964dc9730"
      },
      "outputs": [],
      "source": [
        "# create flat structure from recods -> events -> subqueries\n",
        "\n",
        "rows = []\n",
        "main_fields = ['traceId','queryId','startTime','duration','modelId','catalogId','userId','queryType','catalogName','modelName','user']\n",
        "subquery_fields = ['name','duration','subqueryId']\n",
        "# appending rows\n",
        "for data in records:\n",
        "  events = data['events']\n",
        "  print(events)\n",
        "  for event in events:\n",
        "    for main_field in main_fields:\n",
        "      try:\n",
        "        event['main_'+main_field] = data[main_field]\n",
        "      except:\n",
        "        break\n",
        "\n",
        "    if'subqueries' in event.keys():\n",
        "      subqueries = event['subqueries']\n",
        "      for subquery in subqueries:\n",
        "        for subquery_field in subquery_fields:\n",
        "          try:\n",
        "            event['subquery_'+subquery_field] = subquery[subquery_field]\n",
        "          except:\n",
        "            break\n",
        "\n",
        "    else:\n",
        "      event['subquery_subqueryId'] = None\n",
        "\n",
        "    rows.append(event)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "#define the keys to remove\n",
        "df.drop(columns=['subqueries'], inplace=True)\n",
        "df.rename(columns={'name': 'event_name', 'startTime': 'event_startTime', 'duration': 'event_duration', 'queryId': 'event_queryId'}, inplace=True)\n",
        "df['main_startTime'] = df['main_startTime'].apply(lambda x:datetime.datetime.fromtimestamp(x/1000.0))\n",
        "df['event_startTime'] = df['event_startTime'].apply(lambda x:datetime.datetime.fromtimestamp(x/1000.0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1726060328331,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "pfqJOCtNrPKv"
      },
      "outputs": [],
      "source": [
        "#Create Big Query Schema\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.bigquery.schema import SchemaField\n",
        "from typing import List\n",
        "\n",
        "def generate_bigquery_schema(df: pd.DataFrame) -> List[SchemaField]:\n",
        "    TYPE_MAPPING = {\n",
        "        \"i\": \"INTEGER\",\n",
        "        \"u\": \"NUMERIC\",\n",
        "        \"b\": \"BOOLEAN\",\n",
        "        \"f\": \"FLOAT\",\n",
        "        \"O\": \"STRING\",\n",
        "        \"S\": \"STRING\",\n",
        "        \"U\": \"STRING\",\n",
        "        \"M\": \"TIMESTAMP\",\n",
        "    }\n",
        "    schema = []\n",
        "    for column, dtype in df.dtypes.items():\n",
        "        val = df[column].iloc[0]\n",
        "        mode = \"REPEATED\" if isinstance(val, list) else \"NULLABLE\"\n",
        "\n",
        "        if isinstance(val, dict) or (mode == \"REPEATED\" and isinstance(val[0], dict)):\n",
        "            fields = generate_bigquery_schema(pd.json_normalize(val))\n",
        "        else:\n",
        "            fields = ()\n",
        "\n",
        "        type = \"RECORD\" if fields else TYPE_MAPPING.get(dtype.kind)\n",
        "        schema.append(\n",
        "            SchemaField(\n",
        "                name=column,\n",
        "                field_type=type,\n",
        "                mode=mode,\n",
        "                fields=fields,\n",
        "            )\n",
        "        )\n",
        "    return schema\n",
        "bigquery_schema = generate_bigquery_schema(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3428,
          "status": "ok",
          "timestamp": 1726060351666,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "-Pxzme4LoXY_",
        "outputId": "cf865708-470c-48b1-b6c9-6a5d62f306fd"
      },
      "outputs": [],
      "source": [
        "#Write query log records to gbq\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    # Specify a (partial) schema. All columns are always written to the\n",
        "    # table. The schema is used to assist in data type definitions.\n",
        "    schema=bigquery_schema,\n",
        "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
        "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
        "    # disposition it replaces the table with the loaded data.\n",
        "    write_disposition=\"WRITE_APPEND\",\n",
        ")\n",
        "\n",
        "job = client.load_table_from_dataframe(\n",
        "\n",
        "    df, table_queries_full, job_config=job_config\n",
        ")  # Make an API request.\n",
        "job.result()  # Wait for the job to complete.\n",
        "\n",
        "table = client.get_table(table_queries_full)  # Make an API request.\n",
        "print(\n",
        "    \"Loaded {} rows and {} columns to {}\".format(\n",
        "        table.num_rows, len(table.schema), table_queries_full\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 4,
          "status": "aborted",
          "timestamp": 1726060331619,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "-CKGbOgXs999"
      },
      "outputs": [],
      "source": [
        "del df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "name": "GetAtScaleQueryData",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
